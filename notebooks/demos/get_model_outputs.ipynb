{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting kwilleke@134.2.168.16:3306\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "dj.config[\"enable_python_native_blobs\"] = True\n",
    "dj.config['schema_name'] = \"nnfabrik_color_mei\"\n",
    "schema = dj.schema(\"nnfabrik_color_mei\")\n",
    "dj.config[\"display.limit\"] = 50\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import load\n",
    "\n",
    "from nnfabrik.main import *\n",
    "import nnfabrik\n",
    "from nnfabrik import main, builder\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuralpredictors.measures import corr\n",
    "\n",
    "from nndichromacy.tables.from_nnfabrik import TrainedModel\n",
    "from nndichromacy.tables.from_mei import MEI, MEIMethod, MEISeed, MEISelector, TrainedEnsembleModel\n",
    "\n",
    "fetch_download_path = '/data/fetched_from_attach'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">dataset_fn</p>\n",
       "                                <span class=\"djtooltiptext\">name of the dataset loader function</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">dataset_hash</p>\n",
       "                                <span class=\"djtooltiptext\">hash of the configuration object</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">dataset_config</p>\n",
       "                                <span class=\"djtooltiptext\">dataset configuration object</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">dataset_fabrikant</p>\n",
       "                                <span class=\"djtooltiptext\">Name of the contributor that added this entry</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">dataset_comment</p>\n",
       "                                <span class=\"djtooltiptext\">short description</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">dataset_ts</p>\n",
       "                                <span class=\"djtooltiptext\">UTZ timestamp at time of insertion</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>nndichromacy.datasets.static_loaders</td>\n",
       "<td>304aafff7cf913c98c6e9494ed3fbff9</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>kfranke</td>\n",
       "<td>24197-18-9 normalized</td>\n",
       "<td>2020-08-16 06:02:27</td></tr><tr><td>nndichromacy.datasets.static_loaders</td>\n",
       "<td>78aac2178ebf2d388194e55b2316e656</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>kfranke</td>\n",
       "<td>23656-14-22 normalized</td>\n",
       "<td>2020-08-11 14:49:21</td></tr><tr><td>nndichromacy.datasets.static_loaders</td>\n",
       "<td>9ec87ee36e77a830a15e3b9582f43760</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>kfranke</td>\n",
       "<td>24046-7-6 normalized</td>\n",
       "<td>2020-08-12 08:35:52</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 3</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*dataset_fn    *dataset_hash  dataset_co dataset_fabrik dataset_commen dataset_ts    \n",
       "+------------+ +------------+ +--------+ +------------+ +------------+ +------------+\n",
       "nndichromacy.d 304aafff7cf913 =BLOB=     kfranke        24197-18-9 nor 2020-08-16 06:\n",
       "nndichromacy.d 78aac2178ebf2d =BLOB=     kfranke        23656-14-22 no 2020-08-11 14:\n",
       "nndichromacy.d 9ec87ee36e77a8 =BLOB=     kfranke        24046-7-6 norm 2020-08-12 08:\n",
       " (Total: 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset() & \"dataset_ts > '2020-08-10'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dict(dataset_hash='304aafff7cf913c98c6e9494ed3fbff9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>contains ensemble ids</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">dataset_fn</p>\n",
       "                                <span class=\"djtooltiptext\">name of the dataset loader function</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">dataset_hash</p>\n",
       "                                <span class=\"djtooltiptext\">hash of the configuration object</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">ensemble_hash</p>\n",
       "                                <span class=\"djtooltiptext\">the hash of the ensemble</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">ensemble_comment</p>\n",
       "                                <span class=\"djtooltiptext\">a short comment describing the ensemble</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>nndichromacy.datasets.static_loaders</td>\n",
       "<td>304aafff7cf913c98c6e9494ed3fbff9</td>\n",
       "<td>9b3028070d7080c2e8937c87b4c4e757</td>\n",
       "<td>default</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 1</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*dataset_fn    *dataset_hash  *ensemble_hash ensemble_comme\n",
       "+------------+ +------------+ +------------+ +------------+\n",
       "nndichromacy.d 304aafff7cf913 9b3028070d7080 default       \n",
       " (Total: 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainedEnsembleModel & key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static24197-18-9-preproc0 exists already. Not unpacking static24197-18-9-preproc0.zip\n",
      "static24197-18-9-preproc0 exists already. Not unpacking static24197-18-9-preproc0.zip\n",
      "static24197-18-9-preproc0 exists already. Not unpacking static24197-18-9-preproc0.zip\n",
      "static24197-18-9-preproc0 exists already. Not unpacking static24197-18-9-preproc0.zip\n",
      "static24197-18-9-preproc0 exists already. Not unpacking static24197-18-9-preproc0.zip\n"
     ]
    }
   ],
   "source": [
    "dataloaders, model = (TrainedEnsembleModel & key).load_model()\n",
    "model.eval();\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = list(dataloaders[\"train\"].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a batch of images\n",
    "images, responses = next(iter(dataloaders[\"train\"][data_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2, 36, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# everything that you show to the model has to be a tensor, with 4 dimensions: batch, channels, height, width.\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when making predictions with the model, the gradient will always be computed as well, but here it isn't needed.\n",
    "# the gradient has high demands on the GPU memory, so it's best to simply do all calculations without the gradient with the following statement:\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1107])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output is: Images x Neurons\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4655, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of the first image and first neuron. The result is a tensor on the GPU, for further processing, it's easiest to convert to numpy\n",
    "output[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46546298\n"
     ]
    }
   ],
   "source": [
    "output = output.cpu().numpy()\n",
    "print(output[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching a couple of MEIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_MEIs_to_fetch = 20\n",
    "mei_paths = (MEI & key).fetch(\"mei\", limit=n_MEIs_to_fetch, download_path=fetch_download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the MEIs as GPU Tensors (to be passed to the model)\n",
    "MEIs = torch.stack([torch.load(path).cuda() for path in mei_paths]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to loading the MEIs as images\n",
    "MEIs_images = np.stack([torch.load(path).detach().cpu().numpy().squeeze() for path in mei_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2, 36, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEIs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(MEIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1107])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GPU should have enough memory so that you can pass all MEIs through the model at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching the MEIs in the order of the unit_index (as in the model)\n",
    "mei_paths = (MEISelector*MEI & key).fetch(\"mei\", download_path=fetch_download_path, order_by=\"unit_index\")\n",
    "MEIs = torch.stack([torch.load(path).cuda() for path in mei_paths]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(MEIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you have the full response matrix, and from there it's easiest to convert to numpy.\n",
    "# I'd guess that about 5000 images is the most the the model can take at once, without running out of memory.\n",
    "# So if it's more than that, you can cut it down to batches of 5000, and show it to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
